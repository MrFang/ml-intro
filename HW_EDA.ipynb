{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка библиотек"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для начала работы нам необходимо научиться читать набор данных. В данном домашнем задании мы поработаем с двумя наборами данных.\n",
    "\n",
    "__covid.csv__ ([источник](https://www.kaggle.com/gpreda/covid-world-vaccination-progress)) - статистика по вакцинированию от COVID19 по разным странам. Для данного датасета нет конкретной предсказательной переменной.\n",
    "\n",
    "__hr.csv__ ([источник](https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists)) - набор данных большего размера. Он содержит статистику по людям, проходящим курсы по Big Data & ML. _Target_ - 1 или 0, сменил ли человек работу после прохождения курсов - или нет.\n",
    "\n",
    "Реализуйте методы `read_covid_dataset` и `read_hr_dataset`. Каждый из них принимает на вход путь к набору данных и возвращает выборку `X` и соответствующие метки `y`. В случае _covid_ датасета `y` возвращается как `None`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def read_covid_dataset(path_to_csv):\n",
    "    # Возвращает пару из X и y. X - массив векторов. y - соответствующие векторам метки\n",
    "    return pd.read_csv(path_to_csv), None\n",
    "\n",
    "\n",
    "def read_hr_dataset(path_to_csv):\n",
    "    # Возвращает пару из X и y. X - массив векторов. y - соответствующие векторам метки\n",
    "    data: pd.DataFrame = pd.read_csv(path_to_csv)\n",
    "    return data.drop('target', axis = 1), data['target']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "COVID_DATA_PATH = './hw_EDA_data/covid.csv'\n",
    "HR_DATA_PATH = './hw_EDA_data/hr.csv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_covid, _ = read_covid_dataset(COVID_DATA_PATH)\n",
    "X_hr, y_hr = read_hr_dataset(HR_DATA_PATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA\n",
    "\n",
    "### Задание"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выполните задание для датасетa _hr_.\n",
    "\n",
    "Для дальнейшей работы с данными нужно обработать пропущенные значения в датасете.\n",
    "Существуют различные стратегии обработки пропущенных данных."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.\n",
    "\n",
    "Для числовых признаков постройте распределения признаков. Для категориальных признаков выведите статистику по количеству значений признака."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def split_features(X: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
    "    numeric_features = list(filter(\n",
    "        lambda label: type(X[label].dtype) in [type(np.dtype(np.int64)), type(np.dtype(np.float64))],\n",
    "        X.columns\n",
    "    ))\n",
    "    categorial_features = list(filter(lambda label: label not in numeric_features, X.columns))\n",
    "\n",
    "    return numeric_features, categorial_features\n",
    "\n",
    "numeric_features, categorial_features = split_features(X_hr)\n",
    "\n",
    "_ = X_hr[numeric_features].hist()\n",
    "\n",
    "for feature in X_hr[categorial_features]:\n",
    "    sns.displot(X_hr[feature])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.\n",
    "Удалите все строки, где есть хотя бы одно пропущенное значение признака. Насколько сильно уменьшился размер датасета? Как изменились распределения признаков/статистика по количеству значений признаков?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'Исходный размер датасета hr {X_hr.shape[0]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_hr_dropna = X_hr.dropna()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'Pазмер датасета hr без NaN {X_hr_dropna.shape[0]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: Размер датасета уменьшился более чем в два раза. Статистика по количеству значений в каждой категории уменьшилась соответственно, кроме того, целиком исчезли некоторые категории"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте попробуем избежать сокращения размера датасета."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.\n",
    "Для числовых признаков заполните пропущенные данные средним/медианой/модой данного признака. Объясните свой выбор. (Часть строк с NaN значениями можно удалить, если размер датасета уменьшится <15%)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.\n",
    "Для категориальных признаков заполните пропущенные значения самой встречающейся категорией или создайте отдельную категорию пропущенных значений. Объясните свой выбор. (Часть строк с NaN значениями можно удалить, если размер датасета уменьшится <15%)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: У числовых признаков нет пропущенных значений, поэтому неважно, чем заменять"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from functools import reduce\n",
    "\n",
    "numeric_features, _ = split_features(X_hr)\n",
    "\n",
    "for feature in numeric_features:\n",
    "    print(feature, X_hr[feature].shape[0], X_hr[feature].dropna().shape[0])\n",
    "\n",
    "def fill_na(X: pd.DataFrame, y: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    # Возвращает данные без NaN значений\n",
    "    def get_means(means: dict, label: str) -> dict:\n",
    "        means[label] = X[label].mean()\n",
    "        return means\n",
    "\n",
    "    def get_modes(modes: dict, label: str) -> dict:\n",
    "        modes[label] = X[label].mode()[0]\n",
    "        return modes\n",
    "\n",
    "    numeric_features, categorial_features = split_features(X)\n",
    "    \n",
    "    X_fill = X.fillna(dict(reduce(get_means, numeric_features, {}))) \\\n",
    "        .fillna(dict(reduce(get_modes, categorial_features, {})))\n",
    "    \n",
    "    return X_fill, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_hr_fill, y_hr_fill = fill_na(X_hr, y_hr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. \n",
    "Как изменились распределения признаков/статистика по количеству значений признаков после заполнения пропущенных данных?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "numeric_features, categorial_features = split_features(X_hr_fill)\n",
    "\n",
    "_ = X_hr_fill[numeric_features].hist()\n",
    "\n",
    "for feature in X_hr_fill[categorial_features]:\n",
    "    sns.displot(X_hr_fill[feature])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: Для числовых приззаков в датасете нет NA значений, поэтому никак. В случае категориальных признаков может вызвать перевес доминирующей категории"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание\n",
    "\n",
    "Выполните задание для датасета _covid_.\n",
    "\n",
    "1. Найдите страну, для которой в датасете присутствует 46 дат со статистикой по вакцинации.\n",
    "2. Постройте для этой страны график зависимости _total_vaccinations_ от _date_.\n",
    "3. Заполните пропущенные данные о _total_vaccinations_ для этой страны. Объясните свой выбор."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "groups = X_covid.groupby('country').size()\n",
    "country = groups[groups == 46].first_valid_index()\n",
    "\n",
    "na_rows = X_covid[(X_covid['country'] == country) & (X_covid['total_vaccinations'].isna())]\n",
    "\n",
    "x1, x2, y1, y2 = \\\n",
    "    na_rows.first_valid_index() - 1, \\\n",
    "    na_rows.last_valid_index() + 1, \\\n",
    "    X_covid[(X_covid['country'] == country)].loc[na_rows.first_valid_index() - 1]['total_vaccinations'], \\\n",
    "    X_covid[(X_covid['country'] == country)].loc[na_rows.last_valid_index() + 1]['total_vaccinations']\n",
    "\n",
    "k = (y2 - y1)/(x2 - x1)\n",
    "b = y2 - k*x2\n",
    "\n",
    "def line(x: float) -> float:\n",
    "    return k*x + b\n",
    "\n",
    "# TODO: mutate X_covid"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание \n",
    "Выполните задание для датасета _hr_.\n",
    "\n",
    "Есть ли в данных выбросы? Если да, то скажите, какие и почему Вы считаете их выбросами?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_features, _ = split_features(X_hr)\n",
    "\n",
    "for f1 in numeric_features:\n",
    "    for f2 in numeric_features:\n",
    "        if f1 != f2:\n",
    "            plt.figure()\n",
    "            sns.scatterplot(data=X_hr, x=f1, y=f2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: Согласно графикам выше числовые признаки не имеют выбросов, но, кажется, есть перевес одного из значения для `company_type` и `major_discipline`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание \n",
    "Выполните задание для датасета _hr_.\n",
    "\n",
    "Закодируйте категориальные признаки при помощи One-hot encoding/Label encoding/Frequency encoding. Объясните свой выбор. (Обратите внимание, что некоторые категориальные признаки предполагают ранжирование в своих значениях)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def encode(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Возвращает данные без категориальных признаков\n",
    "\n",
    "    X_encoded = X.replace({\n",
    "        'relevent_experience': { 'Has relevent experience': 1, 'No relevent experience': 2 },\n",
    "        'city': (X.groupby('city').size() / len(X)).to_dict(),\n",
    "        'enrolled_university': { 'Full time course': 2,  'Part time course': 1, 'no_enrollment': 0},\n",
    "        'education_level': { 'Graduate': 0, 'Primary School': 1, 'High School': 2, 'Masters': 3, 'Phd': 4 },\n",
    "        'company_size': (X.groupby('company_size').size() / len(X)).to_dict()\n",
    "    })\n",
    "\n",
    "    X_encoded = pd.get_dummies(X_encoded, prefix=['sex', 'discipline', 'company'], columns=['gender', 'major_discipline', 'company_type'])\n",
    "    X_encoded['experience'] = pd.factorize(X_encoded['experience'])[0].reshape(-1, 1)\n",
    "    X_encoded['last_new_job'] = pd.factorize(X_encoded['last_new_job'])[0].reshape(-1, 1)\n",
    "    return X_encoded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_hr_encode = encode(X_hr_fill)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание \n",
    "Выполните задание для датасета _hr_.\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. \n",
    "Реализуйте функцию undersampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. \n",
    "Реализуйте функцию oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def undersampling(X, y):\n",
    "    # Возвращает данные, сбалансированные методом undersampling\n",
    "    X_under = X.sample(50)\n",
    "    return X_under, y_under\n",
    "\n",
    "def oversampling(X, y):\n",
    "    # Возвращает данные, сбалансированные методом undersampling\n",
    "    return X_over, y_over"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_hr_under, y_hr_under = undersampling(X_hr_encode, y_hr_fill)\n",
    "\n",
    "X_hr_over, y_hr_over = oversampling(X_hr_encode, y_hr_fill)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. \n",
    "Используйте _SMOTE_ для балансировки датасета."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Помимо методов _undersampling_ и _oversampling_ существует подход, генерирующий элементы класса-меньшинства, похожие на уже присутствующие в выборке данных. Такой метод называется _Synthetic Minority Oversampling Technique_ (SMOTE). \n",
    "\n",
    "Метод _SMOTE_ , реализованный в библиотеке `imblearn`, генерирует синтетические примеры при помощи __k-nearest neighbor__ алгоритма (подробнее об этом алгоритме будет рассказано на лекции)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -U imbalanced-learn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = # YOUR_CODE\n",
    "X_hr_SMOTE, y_hr_SMOTE = # YOUR_CODE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.\n",
    "Как изменились распределения признаков при различных тактиках балансирования датасета?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# YOUR CODE"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d22865cb200c2dfdd3f5854500180a39270a2dc4977b5698ff256ed7c9469f1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}