{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка библиотек"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from typing import Tuple, List"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Загрузка данных"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Для начала работы нам необходимо научиться читать набор данных. В данном домашнем задании мы поработаем с двумя наборами данных.\n",
    "\n",
    "__covid.csv__ ([источник](https://www.kaggle.com/gpreda/covid-world-vaccination-progress)) - статистика по вакцинированию от COVID19 по разным странам. Для данного датасета нет конкретной предсказательной переменной.\n",
    "\n",
    "__hr.csv__ ([источник](https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists)) - набор данных большего размера. Он содержит статистику по людям, проходящим курсы по Big Data & ML. _Target_ - 1 или 0, сменил ли человек работу после прохождения курсов - или нет.\n",
    "\n",
    "Реализуйте методы `read_covid_dataset` и `read_hr_dataset`. Каждый из них принимает на вход путь к набору данных и возвращает выборку `X` и соответствующие метки `y`. В случае _covid_ датасета `y` возвращается как `None`. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def read_covid_dataset(path_to_csv):\n",
    "    # Возвращает пару из X и y. X - массив векторов. y - соответствующие векторам метки\n",
    "    return pd.read_csv(path_to_csv), None\n",
    "\n",
    "\n",
    "def read_hr_dataset(path_to_csv):\n",
    "    # Возвращает пару из X и y. X - массив векторов. y - соответствующие векторам метки\n",
    "    data: pd.DataFrame = pd.read_csv(path_to_csv)\n",
    "    return data.drop('target', axis = 1), data['target']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "COVID_DATA_PATH = './hw_EDA_data/covid.csv'\n",
    "HR_DATA_PATH = './hw_EDA_data/hr.csv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_covid, _ = read_covid_dataset(COVID_DATA_PATH)\n",
    "X_hr, y_hr = read_hr_dataset(HR_DATA_PATH)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EDA\n",
    "\n",
    "### Задание"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выполните задание для датасетa _hr_.\n",
    "\n",
    "Для дальнейшей работы с данными нужно обработать пропущенные значения в датасете.\n",
    "Существуют различные стратегии обработки пропущенных данных."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.\n",
    "\n",
    "Для числовых признаков постройте распределения признаков. Для категориальных признаков выведите статистику по количеству значений признака."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def split_features(X: pd.DataFrame) -> Tuple[List[str], List[str]]:\n",
    "    numeric_features = list(filter(\n",
    "        lambda label: type(X[label].dtype) in [type(np.dtype(np.int64)), type(np.dtype(np.float64))],\n",
    "        X.columns\n",
    "    ))\n",
    "    categorial_features = list(filter(lambda label: label not in numeric_features, X.columns))\n",
    "\n",
    "    return numeric_features, categorial_features\n",
    "\n",
    "numeric_features, categorial_features = split_features(X_hr)\n",
    "\n",
    "_ = X_hr[numeric_features].hist()\n",
    "\n",
    "for feature in X_hr[categorial_features]:\n",
    "    sns.displot(X_hr[feature])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.\n",
    "Удалите все строки, где есть хотя бы одно пропущенное значение признака. Насколько сильно уменьшился размер датасета? Как изменились распределения признаков/статистика по количеству значений признаков?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'Исходный размер датасета hr {X_hr.shape[0]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_hr_dropna = X_hr.dropna()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(f'Pазмер датасета hr без NaN {X_hr_dropna.shape[0]}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: Размер датасета уменьшился более чем в два раза. Статистика по количеству значений в каждой категории уменьшилась соответственно, кроме того, целиком исчезли некоторые категории"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Давайте попробуем избежать сокращения размера датасета."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.\n",
    "Для числовых признаков заполните пропущенные данные средним/медианой/модой данного признака. Объясните свой выбор. (Часть строк с NaN значениями можно удалить, если размер датасета уменьшится <15%)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.\n",
    "Для категориальных признаков заполните пропущенные значения самой встречающейся категорией или создайте отдельную категорию пропущенных значений. Объясните свой выбор. (Часть строк с NaN значениями можно удалить, если размер датасета уменьшится <15%)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: У числовых признаков нет пропущенных значений, поэтому неважно, чем заменять"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from functools import reduce\n",
    "\n",
    "numeric_features, _ = split_features(X_hr)\n",
    "\n",
    "for feature in numeric_features:\n",
    "    print(feature, X_hr[feature].shape[0], X_hr[feature].dropna().shape[0])\n",
    "\n",
    "def fill_na(X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    # Возвращает данные без NaN значений\n",
    "    def get_means(means: dict, label: str) -> dict:\n",
    "        means[label] = X[label].mean()\n",
    "        return means\n",
    "\n",
    "    def get_modes(modes: dict, label: str) -> dict:\n",
    "        modes[label] = X[label].mode()[0]\n",
    "        return modes\n",
    "\n",
    "    numeric_features, categorial_features = split_features(X)\n",
    "    \n",
    "    X_fill = X.fillna(dict(reduce(get_means, numeric_features, {}))) \\\n",
    "        .fillna(dict(reduce(get_modes, categorial_features, {})))\n",
    "    \n",
    "    return X_fill, y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_hr_fill, y_hr_fill = fill_na(X_hr, y_hr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 5. \n",
    "Как изменились распределения признаков/статистика по количеству значений признаков после заполнения пропущенных данных?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "numeric_features, categorial_features = split_features(X_hr_fill)\n",
    "\n",
    "_ = X_hr_fill[numeric_features].hist()\n",
    "\n",
    "for feature in X_hr_fill[categorial_features]:\n",
    "    sns.displot(X_hr_fill[feature])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: Для числовых приззаков в датасете нет NA значений, поэтому никак. В случае категориальных признаков может вызвать перевес доминирующей категории"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание\n",
    "\n",
    "Выполните задание для датасета _covid_.\n",
    "\n",
    "1. Найдите страну, для которой в датасете присутствует 46 дат со статистикой по вакцинации.\n",
    "2. Постройте для этой страны график зависимости _total_vaccinations_ от _date_.\n",
    "3. Заполните пропущенные данные о _total_vaccinations_ для этой страны. Объясните свой выбор."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "groups = X_covid.groupby('country').size()\n",
    "country = groups[groups == 46].first_valid_index()\n",
    "\n",
    "sns.lineplot(data=X_covid[X_covid['country'] == country], x='date', y='total_vaccinations')\n",
    "\n",
    "interpolated = X_covid[X_covid['country'] == country][[ 'date', 'total_vaccinations' ]] \\\n",
    "    .set_index('date') \\\n",
    "    .interpolate() \\\n",
    "    .reset_index()\n",
    "\n",
    "tmp = []\n",
    "\n",
    "for row in X_covid.itertuples():\n",
    "    tmp.append(row.total_vaccinations if row.country != country else interpolated[interpolated['date'] == row.date]['total_vaccinations'].iloc[0])\n",
    "\n",
    "X_covid['total_vaccinations'] = pd.Series(tmp)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: Пропущенно небольшое количество данных, которые хорошо интерполируются линией"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание \n",
    "Выполните задание для датасета _hr_.\n",
    "\n",
    "Есть ли в данных выбросы? Если да, то скажите, какие и почему Вы считаете их выбросами?\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_features, _ = split_features(X_hr)\n",
    "\n",
    "for f1 in numeric_features:\n",
    "    for f2 in numeric_features:\n",
    "        if f1 != f2:\n",
    "            plt.figure()\n",
    "            sns.scatterplot(data=X_hr, x=f1, y=f2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: Согласно графикам выше числовые признаки не имеют выбросов, но, кажется, есть перевес одного из значения для `company_type` и `major_discipline`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание \n",
    "Выполните задание для датасета _hr_.\n",
    "\n",
    "Закодируйте категориальные признаки при помощи One-hot encoding/Label encoding/Frequency encoding. Объясните свой выбор. (Обратите внимание, что некоторые категориальные признаки предполагают ранжирование в своих значениях)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def encode(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Возвращает данные без категориальных признаков\n",
    "\n",
    "    X_encoded = X.replace({\n",
    "        'city': (X.groupby('city').size() / len(X)).to_dict(),\n",
    "        'company_size': (X.groupby('company_size').size() / len(X)).to_dict()\n",
    "    })\n",
    "\n",
    "    X_encoded = pd.get_dummies(X_encoded, prefix=['sex', 'discipline', 'company'], columns=['gender', 'major_discipline', 'company_type'])\n",
    "    \n",
    "    X_encoded['experience'] = pd.factorize(X_encoded['experience'])[0].reshape(-1, 1)\n",
    "    X_encoded['last_new_job'] = pd.factorize(X_encoded['last_new_job'])[0].reshape(-1, 1)\n",
    "    X_encoded['education_level'] = pd.factorize(X_encoded['education_level'])[0].reshape(-1, 1)\n",
    "    X_encoded['enrolled_university'] = pd.factorize(X_encoded['enrolled_university'])[0].reshape(-1, 1)\n",
    "    X_encoded['relevent_experience'] = pd.factorize(X_encoded['relevent_experience'])[0].reshape(-1, 1)\n",
    "\n",
    "    return X_encoded"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_hr_encode = encode(X_hr_fill)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: Пол, основная дисциплина и тип компании имеют небольшое кол-во вариаций и, кажется, не должны иметь порядка, поэтому используется One Hot Encoding. Город и размер компании для нас могут иметь значение не как отдельные значения, но как их распределения, поэтому они кодируются Frequency Encoding. Наконец такие параметры как, опыт,уровень образования и время от последней смены работы не просто важны для нас как отдельные значения, но ещё и допускают введение отношения порядка, поэтому можно использовать Label Encoding "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Задание \n",
    "Выполните задание для датасета _hr_.\n",
    "\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1. \n",
    "Реализуйте функцию undersampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2. \n",
    "Реализуйте функцию oversampling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def undersampling(X: pd.DataFrame, y: pd.Series) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    # Возвращает данные, сбалансированные методом undersampling\n",
    "    # Работает только в этом случае, т.к. код знает в какую сторону перевес\n",
    "    n = min(y[y == 0].shape[0], y[y == 1].shape[0])\n",
    "\n",
    "    X_under = X.copy()\n",
    "    X_under['target'] = y\n",
    "    X_under = pd.concat([ X_under[X_under['target'] == 0].sample(n), X_under[X_under['target'] == 1] ])\n",
    "    \n",
    "    return X_under.drop('target', axis = 1), X_under['target']\n",
    "\n",
    "def oversampling(X: pd.DataFrame, y: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:\n",
    "    # Возвращает данные, сбалансированные методом undersampling\n",
    "    # Работает только в этом случае, т.к. код знает в какую сторону перевес\n",
    "    n = min(y[y == 0].shape[0], y[y == 1].shape[0])\n",
    "\n",
    "    X_over = X.copy()\n",
    "    X_over['target'] = y\n",
    "    X_positive = X_over[X_over['target'] == 1]\n",
    "    X_negative = X_over[X_over['target'] == 0]\n",
    "    tmp = []\n",
    "\n",
    "    for _ in range(X_negative.shape[0] // X_positive.shape[0]):\n",
    "        tmp.append(X_positive)\n",
    "    \n",
    "    X_over = pd.concat([ X_negative ] + tmp)\n",
    "\n",
    "    return X_over.drop('target', axis = 1), X_over['target']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_hr_under, y_hr_under = undersampling(X_hr_encode, y_hr_fill)\n",
    "\n",
    "X_hr_over, y_hr_over = oversampling(X_hr_encode, y_hr_fill)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3. \n",
    "Используйте _SMOTE_ для балансировки датасета."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Помимо методов _undersampling_ и _oversampling_ существует подход, генерирующий элементы класса-меньшинства, похожие на уже присутствующие в выборке данных. Такой метод называется _Synthetic Minority Oversampling Technique_ (SMOTE). \n",
    "\n",
    "Метод _SMOTE_ , реализованный в библиотеке `imblearn`, генерирует синтетические примеры при помощи __k-nearest neighbor__ алгоритма (подробнее об этом алгоритме будет рассказано на лекции)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!pip install -U imbalanced-learn"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from random import randint\n",
    "\n",
    "smote = SMOTE(random_state=randint(1, 100))\n",
    "X_hr_SMOTE, y_hr_SMOTE = smote.fit_resample(X_hr_encode, y_hr_fill)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 4.\n",
    "Как изменились распределения признаков при различных тактиках балансирования датасета?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for feature in X_hr_under:\n",
    "  fix, axs = plt.subplots(ncols=3)\n",
    "  sns.histplot(X_hr_under[feature], ax=axs[0])\n",
    "  sns.histplot(X_hr_over[feature], ax=axs[1])\n",
    "  sns.histplot(X_hr_SMOTE[feature], ax=axs[2])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "_Ваш ответ_: В целом, различные распределения слабо отличаются друг от друга"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8d22865cb200c2dfdd3f5854500180a39270a2dc4977b5698ff256ed7c9469f1"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('env': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}